{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "i181561.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "04xWGIzQxw2c",
        "bDwxOC-0xvp9",
        "sn_SwgWKh17a",
        "WuDwhSx0g_wV",
        "m9m5nZ40ue4f",
        "ItMZ3aQrrVcA",
        "fPjdti4MC1NA",
        "J2Pk_bxqJvsh",
        "ChoWN9Z8MduX",
        "77Wd8sPLS_pI"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04xWGIzQxw2c"
      },
      "source": [
        "# Reading Data From Files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1P2437ctspf",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 155
        },
        "outputId": "ab54e106-eaa5-4725-8175-42913f01d24b"
      },
      "source": [
        "from google.colab import files\n",
        "import csv\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "#Reading Ghalib File\n",
        "with open('ghalib.txt', 'rt', encoding=\"utf-8\") as f:\n",
        "    reader = csv.reader(f)\n",
        "    ghalib = list(reader)\n",
        "f.close()\n",
        "\n",
        "#Reading Iqbal File\n",
        "with open('iqbal.txt', 'rt', encoding=\"utf-8\") as f:\n",
        "    reader = csv.reader(f)\n",
        "    iqbal = list(reader)\n",
        "f.close()\n",
        "\n",
        "#Reading Faiz File\n",
        "with open('faiz.txt', 'rt', encoding=\"utf-8\") as f:\n",
        "    reader = csv.reader(f)\n",
        "    faiz = list(reader)\n",
        "f.close()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-ca0ef5d5-82a8-4157-9bbb-1234d0be525b\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-ca0ef5d5-82a8-4157-9bbb-1234d0be525b\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving iqbal.txt to iqbal.txt\n",
            "Saving ghalib.txt to ghalib.txt\n",
            "Saving faiz.txt to faiz.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDwxOC-0xvp9"
      },
      "source": [
        "#Filtering the Sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkFokWNQyk5E"
      },
      "source": [
        "import re\n",
        "\n",
        "ghalibFiltered = []\n",
        "iqbalFiltered = []\n",
        "faizFiltered = []\n",
        "\n",
        "for one in ghalib:\n",
        "\n",
        "  if len(one) == 0:\n",
        "    continue\n",
        "\n",
        "  if (one[0] == \"\") or (re.search('[٪]', one[0])) or (re.search('[a-zA-Z]', one[0])) or (re.search('[%]', one[0])) or all(s.isspace() for s in one[0]):\n",
        "    continue\n",
        "  \n",
        "  ghalibFiltered.append(one[0])\n",
        "\n",
        "for one in iqbal:\n",
        "\n",
        "  if len(one) == 0:\n",
        "    continue\n",
        "\n",
        "  if (one[0] == \"\") or (re.search('[٪]', one[0])) or (re.search('[a-zA-Z]', one[0])) or (re.search('[%]', one[0])) or all(s.isspace() for s in one[0]):\n",
        "    continue\n",
        "\n",
        "  iqbalFiltered.append(one[0])\n",
        "\n",
        "for one in faiz:\n",
        "\n",
        "  if len(one) == 0:\n",
        "    continue\n",
        "\n",
        "  if (one[0] == \"\") or (re.search('[٪]', one[0])) or (re.search('[a-zA-Z]', one[0])) or (re.search('[%]', one[0])) or all(s.isspace() for s in one[0]):\n",
        "    continue\n",
        "    \n",
        "  faizFiltered.append(one[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2usRaN2mo6J"
      },
      "source": [
        "#Start Words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmh_hHnUmsEi"
      },
      "source": [
        "startWordsNonUnique = []\n",
        "\n",
        "for one in ghalibFiltered:\n",
        "  startWordsNonUnique.append(one.split(' ')[0])\n",
        "\n",
        "for one in iqbalFiltered:\n",
        "  startWordsNonUnique.append(one.split(' ')[0])\n",
        "\n",
        "for one in faizFiltered:\n",
        "  startWordsNonUnique.append(one.split(' ')[0])\n",
        "\n",
        "startWords = set(startWordsNonUnique)\n",
        "startWords = list(startWords)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sn_SwgWKh17a"
      },
      "source": [
        "#End Words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwz0JoGYh3ad"
      },
      "source": [
        "endWordsNonUnique = []\n",
        "\n",
        "for one in ghalibFiltered:\n",
        "  endWordsNonUnique.append(one.split(' ')[-1])\n",
        "\n",
        "for one in iqbalFiltered:\n",
        "  endWordsNonUnique.append(one.split(' ')[-1])\n",
        "\n",
        "for one in faizFiltered:\n",
        "  endWordsNonUnique.append(one.split(' ')[-1])\n",
        "\n",
        "endWords = set(endWordsNonUnique)\n",
        "endWords = list(endWords)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WuDwhSx0g_wV"
      },
      "source": [
        "#Unigram Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcE7nR7bhCqU"
      },
      "source": [
        "from random import randrange, randint\n",
        "\n",
        "def generateUnigramModel():\n",
        "  ghalibWords = []\n",
        "  iqbalWords = []\n",
        "  faizWords = []\n",
        "\n",
        "  for one in ghalibFiltered:\n",
        "    splitted = one.split(' ')\n",
        "    for word in splitted:\n",
        "      if (word.strip() == '') or (word.strip() == ',') or (word.strip() == '\\''):\n",
        "        continue\n",
        "      ghalibWords.append(word.strip(' '))\n",
        "\n",
        "  for one in iqbalFiltered:\n",
        "    splitted = one.split(' ')\n",
        "    for word in splitted:\n",
        "      if (word.strip() == '') or (word.strip() == ',') or (word.strip() == '\\''):\n",
        "        continue\n",
        "      iqbalWords.append(word.strip())\n",
        "\n",
        "  for one in faizFiltered:\n",
        "    splitted = one.split(' ')\n",
        "    for word in splitted:\n",
        "      if (word.strip() == '') or (word.strip() == ',') or (word.strip() == '\\''):\n",
        "        continue\n",
        "      faizWords.append(word.strip())\n",
        "\n",
        "  corpusWords = ghalibWords + iqbalWords + faizWords\n",
        "\n",
        "  unigrams = set(corpusWords)\n",
        "  unigrams = list(unigrams)\n",
        "\n",
        "  unigramsProbabilities = {}\n",
        "\n",
        "  for word in unigrams:\n",
        "    unigramsProbabilities[word] = (corpusWords.count(word) / len(unigrams))\n",
        "\n",
        "  return unigrams, unigramsProbabilities\n",
        "\n",
        "unigrams, unigramProbabilities = generateUnigramModel()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CJaaLOjp8B9"
      },
      "source": [
        "#Unigram Stanzas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTb-fhlpp-S6",
        "outputId": "5235d94a-1240-4ca3-8b12-a8c20760a928"
      },
      "source": [
        "def generateUnigramStanza(unigrams, probabilities):\n",
        "\n",
        "  stanza = []\n",
        "\n",
        "  for i in range(12):\n",
        "\n",
        "    verseLength = randint(7,10)\n",
        "\n",
        "    #START WORD\n",
        "    verse = startWords[randrange(0, len(startWords))]\n",
        "\n",
        "    #MID WORDS\n",
        "    for j in range(verseLength-2):\n",
        "      randomWord = randrange(0, len(unigrams))\n",
        "  \n",
        "      verse = verse + \" \" + unigrams[randomWord]\n",
        "\n",
        "    #END WORDS\n",
        "    randomLastWord = randrange(0, len(endWords))\n",
        "    verse = verse + \" \" + endWords[randomLastWord]\n",
        "\n",
        "    stanza.append(verse)\n",
        "\n",
        "  i = 1\n",
        "  for verse in stanza:\n",
        "    print(verse)\n",
        "\n",
        "    if i%4 == 0:\n",
        "      print()\n",
        "    i += 1\n",
        "\n",
        "generateUnigramStanza(unigrams, unigramProbabilities)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "آگے غریبی سادہ فلک! مشرق نے: چالاک\n",
            "فریبِ عداوتِ زر مستانہ آبیارِ الِف فوتِ رشک\n",
            "دکھاؤں سَر نظری خر زارِ جانیہائے میرا\n",
            "برہنہ اتحاد دشمنوں انبار درد محال شوخیاں نفس‘ اطفال تھے\n",
            "\n",
            "رکھتے غنچہ کشتِ شوخیِ لکھوائے آبرو خُود فقیروں انداز\n",
            "پہنچ دکھاتی ‘‘ قیامت شے وضع غافل\n",
            "شہرۂ ہلا رسائی چینیاں داراب خسرو رباب گہر ستمہائے آغوش\n",
            "قاصد دانا مشک قد‘ سمجھتی دریائے جفا‘ جاناں پابندی\n",
            "\n",
            "لکھی مصرع صدا سلسبیل ادراک کشایش بہتر سے! ہے! اندھیری\n",
            "ضعف سکے کرنیں عصاۓ فُرصت کشتوں آشیانہ\n",
            "آتے کیوں بڑھتا شیر آدھ وانگبیں انسان معمورِ سلیماں دوانے\n",
            "ایمان مرہمِ اسي سائے قدح تختۂ ایذا ہر تو\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9m5nZ40ue4f"
      },
      "source": [
        "#Bigram Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lp1PWKglugWK"
      },
      "source": [
        "import spacy\n",
        "\n",
        "def generateBigramModel():\n",
        "\n",
        "  unlp = spacy.blank('ur')\n",
        "\n",
        "  allCorpusSentences = ghalibFiltered + iqbalFiltered + faizFiltered\n",
        "\n",
        "  bigrams = list()\n",
        "  bigramsProbabilities = {}\n",
        "\n",
        "  #Generating Bigrams\n",
        "  for one in allCorpusSentences:\n",
        "    sentence = unlp(one)\n",
        "    for i in range(len(sentence) - 1):\n",
        "      w1 = sentence[i]\n",
        "      w2 = sentence[i+1]\n",
        "      bigrams.append(tuple((w1, w2)))\n",
        "\n",
        "  #Filtering out Unique Bigrams\n",
        "  bigrams = set(bigrams)\n",
        "  bigrams = list(bigrams)\n",
        "\n",
        "  #Generating Their Probabilities\n",
        "  for x in bigrams:\n",
        "    word = str(x[0]) + \" \" + str(x[1])\n",
        "\n",
        "    count = 0\n",
        "    for one in allCorpusSentences:\n",
        "      if word in one:\n",
        "        count += 1\n",
        "\n",
        "    bigramsProbabilities[word] = count / len(bigrams)\n",
        "\n",
        "  return bigrams, bigramsProbabilities\n",
        "\n",
        "bigrams, bigramsProbabilities = generateBigramModel()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ItMZ3aQrrVcA"
      },
      "source": [
        "#Bigram Stanzas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_StPPqzmrW5o",
        "outputId": "61300eca-2dfa-4764-f460-3534d7a0c055"
      },
      "source": [
        "def getBigramWord(prevWord):\n",
        "  #NewWords Possibilities\n",
        "  possibilities = []\n",
        "  for x in bigrams:\n",
        "    if str(x[0]) == prevWord:\n",
        "      possibilities.append(str(x[0]) + \" \" + str(x[1]))\n",
        "  \n",
        "  #No Further Possibility, Select Random From the List of Unigrams\n",
        "  if len(possibilities) == 0:\n",
        "    while True:\n",
        "      randProb = randrange(0, len(unigrams))\n",
        "      lastWord = unigrams[randProb]\n",
        "\n",
        "      # Word should not be start or end word\n",
        "      if (lastWord not in startWords) and (lastWord not in endWords):\n",
        "        break\n",
        "    return lastWord  \n",
        "\n",
        "  #Seperating the Probabilites of Filtered Possibilities from All\n",
        "  possibilitiesProbs = {}\n",
        "  for x in possibilities:\n",
        "    possibilitiesProbs[x] = bigramsProbabilities[x]\n",
        "\n",
        "  #Sorting the Possibilities according to their possibilities\n",
        "  possibilitiesProbsSorted = {}\n",
        "  sortedKeys = sorted(possibilitiesProbs, key=possibilitiesProbs.get)\n",
        "  for w in sortedKeys:\n",
        "    possibilitiesProbsSorted[w] = possibilitiesProbs[w]\n",
        "\n",
        "  #Selecting the Pair with Random Top 10 Highest Probability\n",
        "  if len(possibilitiesProbsSorted) > 9:\n",
        "    higherLimit = 10\n",
        "  else:\n",
        "    higherLimit = len(possibilitiesProbsSorted)\n",
        "\n",
        "  maxProb = randrange(0, higherLimit)\n",
        "  maxProbWord = list(possibilitiesProbsSorted.keys())[maxProb]        \n",
        "\n",
        "  lastWord = maxProbWord.split(' ')[-1]\n",
        "\n",
        "  return lastWord\n",
        "\n",
        "#CHOOSING END WORD WHO SHOULD BE INCLUDED IN BIGRAM\n",
        "def bigramEndWord(prevWord):\n",
        "  for x in bigrams:\n",
        "    if (str(x[0]) == prevWord) and (str(x[1]) in endWords):\n",
        "      return str(x[1])\n",
        "  return None\n",
        "\n",
        "def generateBigramStanza(bigrams, probabilities):\n",
        "\n",
        "  stanza = []\n",
        "  \n",
        "  for i in range(12):\n",
        "    verseLength = randint(7,10)\n",
        "\n",
        "    #START WORD\n",
        "    verse = startWords[randrange(0, len(startWords))]\n",
        "    lastWord = verse\n",
        "\n",
        "    #MID WORDS\n",
        "    for j in range(verseLength-1):\n",
        "\n",
        "      #END WORD\n",
        "      if j == (verseLength-2):\n",
        "        lastWord = bigramEndWord(lastWord)\n",
        "\n",
        "        #END WORD IS FOUND\n",
        "        if lastWord is not None:\n",
        "          verse = verse + \" \" + lastWord\n",
        "          break\n",
        "\n",
        "      #FINDING BIGRAM\n",
        "      lastWord = getBigramWord(lastWord)\n",
        "\n",
        "      #APPENDING IT TO VERSE\n",
        "      verse = verse + \" \" + lastWord\n",
        "\n",
        "    stanza.append(verse)\n",
        "\n",
        "  i = 1\n",
        "  for verse in stanza:\n",
        "    print(verse)\n",
        "    if i%4 == 0:\n",
        "      print()\n",
        "    i += 1\n",
        "\n",
        "generateBigramStanza(bigrams, bigramsProbabilities)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "طاقت‘ ہلاہل کو ! تماشا ہوا دیکھا\n",
            "ہمتِ باطل سے فائدہ اخفائے حال کھلتا نہیں اگرچہ فطرت\n",
            "خوبرویوں نے ‘ دابتے ہیں مجبور پیدائی کتب\n",
            "آئے وہ رنگ ہے محیط میں ؟ کہاں کا چراغ\n",
            "\n",
            "چل باد اسد ! ہوا بھی ہوتا ہے\n",
            "گلدستہ نگاہ میں ہوئیں جگ ہنسائیاں کیا علم چارہ ساز\n",
            "چمن اور بات صبر طلب کی خبر\n",
            "مردمک ہے فرنگی شیشہ باز کا چراغ\n",
            "\n",
            "اس انداز بدلے کسی رنگ پر بلاتی رہی نہ تھمتا\n",
            "مانع نگاہ آئنہ ہے لغت ہائے وفا\n",
            "جاتا ہے چنگ و گلشن کو آب جو حجاب\n",
            "آرایش جمال دلفروز صورت مہر وَش کے فتنے کو\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPjdti4MC1NA"
      },
      "source": [
        "#Trigram Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCSVI4FrC3sn"
      },
      "source": [
        "def generateTrigramModel():\n",
        "\n",
        "  unlp = spacy.blank('ur')\n",
        "\n",
        "  allCorpusSentences = ghalibFiltered + iqbalFiltered + faizFiltered\n",
        "\n",
        "  trigrams = list()\n",
        "  trigramsProbabilities = {}\n",
        "\n",
        "  #Generating Trigrams\n",
        "  for one in allCorpusSentences:\n",
        "    sentence = unlp(one)\n",
        "    for i in range(len(sentence) - 2):\n",
        "      w1 = sentence[i]\n",
        "      w2 = sentence[i+1]\n",
        "      w3 = sentence[i+2]\n",
        "      trigrams.append(tuple((w1, w2, w3)))\n",
        "\n",
        "  #Filtering out Unique Trigrams\n",
        "  trigrams = set(trigrams)\n",
        "  trigrams = list(trigrams)\n",
        "\n",
        "  #Generating Their Probabilities\n",
        "  for x in trigrams:\n",
        "    word = str(x[0]) + \" \" + str(x[1]) + \" \" + str(x[2])\n",
        "\n",
        "    count = 0\n",
        "    for one in allCorpusSentences:\n",
        "      if word in one[0]:\n",
        "        count += 1\n",
        "\n",
        "    trigramsProbabilities[word] = count / len(trigrams)\n",
        "\n",
        "  return trigrams, trigramsProbabilities\n",
        "\n",
        "trigrams, trigramsProbabilities = generateTrigramModel()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2Pk_bxqJvsh"
      },
      "source": [
        "#Trigram Stanza"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4y6e2HPGJxmH",
        "outputId": "3b070dc0-3848-4d03-8af4-1d51c33c2d59"
      },
      "source": [
        "def getTrigramWords(secondLastWord, lastWord):\n",
        "  #NewWords Possibilities\n",
        "  possibilities = []\n",
        "  for x in trigrams:\n",
        "    if (str(x[0]) == secondLastWord) and (str(x[1]) == lastWord):\n",
        "      possibilities.append(str(x[0]) + \" \" + str(x[1]) + \" \" + str(x[2]))\n",
        "  \n",
        "  #No Further Possibility, Select From the List of Bigrams\n",
        "  if len(possibilities) == 0:\n",
        "    lastWord = getBigramWord(secondLastWord)\n",
        "    return lastWord\n",
        "\n",
        "  #Seperating the Probabilites of Filtered Possibilities from All\n",
        "  possibilitiesProbs = {}\n",
        "  for x in possibilities:\n",
        "    possibilitiesProbs[x] = trigramsProbabilities[x]\n",
        "\n",
        "  #Sorting the Possibilities according to their possibilities\n",
        "  possibilitiesProbsSorted = {}\n",
        "  sortedKeys = sorted(possibilitiesProbs, key=possibilitiesProbs.get)\n",
        "  for w in sortedKeys:\n",
        "    possibilitiesProbsSorted[w] = possibilitiesProbs[w]\n",
        "\n",
        "  #Selecting the Pair with Random Top 10 Highest Probability\n",
        "  if len(possibilitiesProbsSorted) > 9:\n",
        "    higherLimit = 10\n",
        "  else:\n",
        "    higherLimit = len(possibilitiesProbsSorted)\n",
        "\n",
        "  maxProb = randrange(0, higherLimit)\n",
        "  maxProbWord = list(possibilitiesProbsSorted.keys())[maxProb]        \n",
        "  lastWord = maxProbWord.split(' ')[-1]\n",
        "\n",
        "  return lastWord\n",
        "\n",
        "#CHOOSING END WORD WHO SHOULD BE INCLUDED IN TRIGRAM\n",
        "def trigramEndWord(secondLastWord, lastWord):\n",
        "  for x in trigrams:\n",
        "    if (str(x[0]) == secondLastWord) and (str(x[1]) == lastWord) and (str(x[2]) in endWords):\n",
        "      return str(x[2])\n",
        "  return None\n",
        "\n",
        "def generateTrigramStanza(trigrams, probabilities):\n",
        "\n",
        "  stanza = []\n",
        "  \n",
        "  for i in range(12):\n",
        "    verseLength = randint(7,10)\n",
        "\n",
        "    #START WORD, CHOOSE FROM START WORDS WHICH COME IN BIGRAM\n",
        "    secondLastWord = startWords[randrange(0, len(startWords))]\n",
        "    lastWord = getBigramWord(secondLastWord)\n",
        "    verse = secondLastWord + \" \" + lastWord\n",
        "\n",
        "    #MID WORDS\n",
        "    for j in range(verseLength-2):\n",
        "\n",
        "      #END WORD\n",
        "      if j == (verseLength-3):\n",
        "        lastWord = trigramEndWord(secondLastWord, lastWord)\n",
        "\n",
        "        #END WORD IS FOUND\n",
        "        if lastWord is not None:\n",
        "          verse = verse + \" \" + lastWord\n",
        "          break\n",
        "\n",
        "      #FINDING TRIGRAM\n",
        "      secondLastWord = lastWord\n",
        "      lastWord = getTrigramWords(secondLastWord, lastWord)\n",
        "\n",
        "      #APPENDING IT TO VERSE\n",
        "      verse = verse + \" \" + lastWord\n",
        "\n",
        "    stanza.append(verse)\n",
        "\n",
        "  i = 1\n",
        "  for verse in stanza:\n",
        "    print(verse)\n",
        "    if i%4 == 0:\n",
        "      print()\n",
        "    i += 1\n",
        "\n",
        "generateTrigramStanza(trigrams, trigramsProbabilities)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "شوخیِ رفتارِ باغ نہیں میں بالیدنِ فقرِ\n",
            "باعثِ ایذا ہے ؟ کہ تماشا جل رہی ہے راج\n",
            "سفینہ سنبھال کر خاک ہوا کو ! ہر حلقہ یاں\n",
            "پنپ نہ لاوے تاب و ماہ سے\n",
            "\n",
            "خلد کا دروازہ ہوں تیرا نقشِ حیرت ہے\n",
            "زیست ان آنکھوں کے دھمکانے نہ خداوند ، کیا\n",
            "ظلمت ھے ! تماشا دیکھنے والے غریبی سے رُوح بت\n",
            "چپ تھا سر وَ بالِ دوش پہ دریا ہو رک\n",
            "\n",
            "اگر میرے گہر کی آج ندیم ! ہر شوق نہیں\n",
            "چپک رہا افسردگی اے غافل تجلی شمع دلفروز‘\n",
            "آمدورفتِ نفس مرا سودا کب تک سنے گی کیا آبرو\n",
            "رات کو نوید ہو : یک عرصہ آفاق تنگ\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ChoWN9Z8MduX"
      },
      "source": [
        "#Backward Bigram Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmB5A-uvMfyl"
      },
      "source": [
        "def generateBackwardBigramModel():\n",
        "\n",
        "  unlp = spacy.blank('ur')\n",
        "\n",
        "  allCorpusSentences = ghalibFiltered + iqbalFiltered + faizFiltered\n",
        "\n",
        "  bBigrams = list()\n",
        "  bBigramsProbabilities = {}\n",
        "\n",
        "  #Generating Backward Bigrams\n",
        "  for one in allCorpusSentences:\n",
        "    sentence = unlp(one)\n",
        "    for i in range(len(sentence)-1, -1 ,-1):\n",
        "      w1 = sentence[i]\n",
        "      w2 = sentence[i-1]\n",
        "      bBigrams.append(tuple((w1, w2)))\n",
        "\n",
        "  bBigrams = set(bBigrams)\n",
        "  bBigrams = list(bBigrams)\n",
        "\n",
        "  #Generating Their Probabilities\n",
        "  for x in bBigrams:\n",
        "    origWord = str(x[1]) + \" \" + str(x[0]) \n",
        "    word = str(x[0]) + \" \" + str(x[1])\n",
        "\n",
        "    count = 0\n",
        "    for one in allCorpusSentences:\n",
        "      if origWord in one[0]:\n",
        "        count += 1\n",
        "\n",
        "    bBigramsProbabilities[word] = count / len(bBigrams)\n",
        "\n",
        "  return bBigrams, bBigramsProbabilities\n",
        "\n",
        "backwardBigrams, backwardBigramsProbabilities = generateBackwardBigramModel()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77Wd8sPLS_pI"
      },
      "source": [
        "#Backward Bigram Stanza"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TDtDNtYAO2He",
        "outputId": "a3737de0-e1b1-4c32-cf40-b3f76ccbc539"
      },
      "source": [
        "def getBackwardBigramWord(nextWord):\n",
        "  #NewWords Possibilities\n",
        "  possibilities = []\n",
        "  for x in backwardBigrams:\n",
        "    if str(x[0]) == nextWord:\n",
        "      possibilities.append(str(x[0]) + \" \" + str(x[1]))\n",
        "  \n",
        "  #No Further Possibility, Select Random From the List of Unigrams\n",
        "  if len(possibilities) == 0:\n",
        "    while True:\n",
        "      randProb = randrange(0, len(unigrams))\n",
        "      nextWord = unigrams[randProb]\n",
        "\n",
        "      # Word should not be start or end word\n",
        "      if (nextWord not in startWords) and (nextWord not in endWords):\n",
        "        break\n",
        "    return nextWord  \n",
        "\n",
        "  #Seperating the Probabilites of Filtered Possibilities from All\n",
        "  possibilitiesProbs = {}\n",
        "  for x in possibilities:\n",
        "    possibilitiesProbs[x] = backwardBigramsProbabilities[x]\n",
        "\n",
        "  #Sorting the Possibilities according to their possibilities\n",
        "  possibilitiesProbsSorted = {}\n",
        "  sortedKeys = sorted(possibilitiesProbs, key=possibilitiesProbs.get)\n",
        "  for w in sortedKeys:\n",
        "    possibilitiesProbsSorted[w] = possibilitiesProbs[w]\n",
        "\n",
        "  #Selecting the Pair with Random Top 10 Highest Probability\n",
        "  if len(possibilitiesProbsSorted) > 9:\n",
        "    higherLimit = 10\n",
        "  else:\n",
        "    higherLimit = len(possibilitiesProbsSorted)\n",
        "\n",
        "  maxProb = randrange(0, higherLimit)\n",
        "  maxProbWord = list(possibilitiesProbsSorted.keys())[maxProb]        \n",
        "\n",
        "  nextWord = maxProbWord.split(' ')[-1]\n",
        "\n",
        "  return nextWord\n",
        "\n",
        "#CHOOSING START WORD WHO SHOULD BE INCLUDED IN BIGRAM\n",
        "def backwardBigramStartWord(nextWord):\n",
        "  for x in backwardBigrams:\n",
        "    if (str(x[0]) == nextWord) and (str(x[1]) in endWords):\n",
        "      return str(x[1])\n",
        "  return None\n",
        "\n",
        "def generateBackwardBigramStanza(bBigrams, probabilities):\n",
        "\n",
        "  stanza = []\n",
        "  \n",
        "  for i in range(12):\n",
        "    verseLength = randint(7,10)\n",
        "\n",
        "    #END WORD\n",
        "    verse = startWords[randrange(0, len(endWords))]\n",
        "    firstWord = verse\n",
        "\n",
        "    #MID WORDS\n",
        "    for j in range(verseLength-1):\n",
        "\n",
        "      #START WORD\n",
        "      if j == (verseLength-2):\n",
        "        firstWord = backwardBigramStartWord(firstWord)\n",
        "\n",
        "        #START WORD IS FOUND\n",
        "        if firstWord is not None:\n",
        "          verse = firstWord + \" \" + verse\n",
        "          break\n",
        "\n",
        "      #FINDING BACKWARD BIGRAM\n",
        "      firstWord = getBackwardBigramWord(firstWord)\n",
        "\n",
        "      #APPENDING IT TO VERSE\n",
        "      verse = firstWord + \" \" + verse\n",
        "\n",
        "    stanza.append(verse)\n",
        "\n",
        "  i = 1\n",
        "  for verse in stanza:\n",
        "    print(verse)\n",
        "    if i%4 == 0:\n",
        "      print()\n",
        "    i += 1\n",
        "\n",
        "generateBackwardBigramStanza(backwardBigrams, backwardBigramsProbabilities)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "انتظار تھا واں سے آگے آتی ہے لباسِ\n",
            "کا منہ سے پرافشاں نکلا جو چپ\n",
            "! یہ مرحلہ ء رسوا ہوئے سر غالب ورنہ بغل\n",
            "اسدؔ فتنہ و شادی ہے پہ ہاتھ\n",
            "\n",
            "نکلا آنکھ سے جام یار پر ہنسی آگے رہنے\n",
            "وہ بھی خیال آیا کہ غالب اگ رہا عرضِ\n",
            "ہوں اور بھی تیرا جہاں تیرا محمد\n",
            "آزاد و بازوئے قاتل دعا کیا سناؤں اقبال کا چرایا\n",
            "\n",
            "لگا ناگہاں اس قدر جو اک تار بھی نگاہ\n",
            "پایا صبح یک درس تپش در پہ دم شمشیر\n",
            "کہ ہے جو ممنون معاصی بھی ہم حمد\n",
            "تماشا دیکھ کر ‘ اور بات عدو کریں\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfwOpuE0bRnR"
      },
      "source": [
        "#Bidirectional Bigram Stanza"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNpEPjBabVRt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "875037cd-0b6f-4661-e285-9ed7b06f8435"
      },
      "source": [
        "def generateBidirectionalBigramStanza():\n",
        "\n",
        "  stanza = []\n",
        "  \n",
        "  for i in range(12):\n",
        "    verseLength = randint(7,9)\n",
        "\n",
        "    #STARTING FROM MID WORD WHICH IS NEITHER START WORD OR END WORD\n",
        "    while True:\n",
        "      x = randrange(0, len(bigrams))\n",
        "      if (str(bigrams[x][0]) not in startWords) and (str(bigrams[x][0]) not in endWords):\n",
        "        midWord = str(bigrams[x][0])\n",
        "        break\n",
        "\n",
        "    #USING BIGRAM TO FIND FORWARD WORDS\n",
        "    lastVerse = \"\"\n",
        "    nextWord = midWord\n",
        "    for j in range(verseLength//2):\n",
        "\n",
        "      #START WORD\n",
        "      if j == ((verseLength//2) -1):\n",
        "        nextWord = bigramEndWord(nextWord)\n",
        "\n",
        "        #START WORD IS FOUND\n",
        "        if nextWord is not None:\n",
        "          lastVerse = lastVerse + \" \" + nextWord\n",
        "          break\n",
        "\n",
        "      #FINDING FORWARD BIGRAM\n",
        "      nextWord = getBigramWord(nextWord)\n",
        "\n",
        "      #APPENDING IT TO VERSE\n",
        "      lastVerse = lastVerse + \" \" + nextWord\n",
        "\n",
        "    #USING BACKWARD BIGRAM TO FIND PREVIOUS WORDS\n",
        "    firstVerse = \"\"\n",
        "    prevWord = midWord\n",
        "    for j in range(verseLength//2):\n",
        "\n",
        "      #END WORD\n",
        "      if j == ((verseLength//2) -1):\n",
        "        prevWord = backwardBigramStartWord(prevWord)\n",
        "\n",
        "        #END WORD IS FOUND\n",
        "        if prevWord is not None:\n",
        "          firstVerse = prevWord + \" \" + firstVerse\n",
        "          break\n",
        "\n",
        "      #FINDING BACKWARD BIGRAM\n",
        "      prevWord = getBackwardBigramWord(prevWord)\n",
        "\n",
        "      #APPENDING IT TO VERSE\n",
        "      firstVerse = prevWord + \" \" + firstVerse\n",
        "\n",
        "    #COMBINING FIRST VERSE, MID WORD AND LAST VERSE\n",
        "    verse = firstVerse + midWord + lastVerse\n",
        "\n",
        "    stanza.append(verse)\n",
        "\n",
        "  i = 1\n",
        "  for verse in stanza:\n",
        "    print(verse)\n",
        "    if i%4 == 0:\n",
        "      print()\n",
        "    i += 1\n",
        "\n",
        "generateBidirectionalBigramStanza()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "عرض کر سکے کون جیتا نہیں ؟ کیجیے کیا\n",
            "کیا کہ ساحل دریائے خوں جو حجاب\n",
            "تو سمجھا ہوا برا کیوں خوار ہوگا\n",
            "دل کا یہ بے لوث عبادت کرتا ہے زیادہ\n",
            "\n",
            "پر کہے بغیر ‘ صبا سے چل اے غافل\n",
            "گل کو ‘ ہائے خوباں ہوں میں\n",
            "خورسند آزاد و جم و نالہ میں\n",
            "واسطے تھوڑی سی آب چہ مستانہ می رود انگور\n",
            "\n",
            "کیا کم از سیلیِ استاد ‘ کافر نہیں آتی\n",
            "پر کہے بغیر ‘ بجائے خود غلطیہائے عزیزاں ،فلسفہ\n",
            "مکرر کسریٰ سے حریفِ منتِ دستار ہے محیط میں\n",
            "کہ ہم مشقِ ستم سکھلائے گا کوئی غالب !\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJWXYhrysley"
      },
      "source": [
        "#DOCUMENTATION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmptUK_fsq_L"
      },
      "source": [
        "1.   I first loaded the corpus and filtered out english sentences or special characters.\n",
        "2.   Then i made a list of StartWords and EndWords from the corpus.\n",
        "3.   For n-gram models, i used StartWords to choose the first word, then i used n-grams to fill the middle words using random n-gram word from top 10 highest probability value and lastly i used list of endWords to get the final word if it is included in that n-gram model.\n",
        "4.   For Bigram Model, if i didn't find any bigram word in middle, then i choosed a random unigram word to fill that word.\n",
        "5.   For Trigram Model, if i used bigram to generate the first two words, then in case of me not finding any trigram, i used bigram to fill that gap.\n",
        "6.   Backward bigram model was also made using same steps mentioned above but the sequence started from end to start.\n",
        "7.   In case of bidirectional bigram model, i first used a random bigram middle word, then i used bigram model to find the half stanza after that middleword and i used reverse bigram model to find the half stanza before that middle word. Finally i combined them to generate a stanza.\n",
        "8.   Trigram is better than bigram. Bigram is better than unigram. Reverse bigram is as good as bigram and bidirectional bigram is worse than bigram according to my research."
      ]
    }
  ]
}